{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "DATA_PATH = 'data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from torchvision.datasets import ImageFolder\n",
    "from imgaug import augmenters as iaa\n",
    "import imgaug as ia\n",
    "from torch.utils.data import ConcatDataset, DataLoader\n",
    "\n",
    "\n",
    "train_path = os.path.join(DATA_PATH, 'train')\n",
    "val_path = os.path.join(DATA_PATH, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 100\n",
    "IMAGE_SHAPE = 224\n",
    "BATCH_SIZE = 12\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "use_cuda = False\n",
    "dtype = torch.cuda.FloatTensor if use_cuda else torch.FloatTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(False, torch.FloatTensor)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "use_cuda, dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainAugTransform:\n",
    "    def __init__(self, rotation):\n",
    "        self.aug = iaa.Sequential([\n",
    "            iaa.Scale((IMAGE_SHAPE, IMAGE_SHAPE)),\n",
    "            iaa.Sometimes(0.25, iaa.GaussianBlur(sigma=(0, 3.0))),\n",
    "            iaa.Fliplr(0.5),\n",
    "            iaa.Affine(rotate=rotation, mode='symmetric'),\n",
    "            iaa.Sometimes(0.2, iaa.Dropout(p=(0, 0.1))),\n",
    "            iaa.AddToHueAndSaturation(value=(-10, 10), per_channel=True)\n",
    "        ])\n",
    "      \n",
    "    def __call__(self, img):\n",
    "        img = np.array(img)\n",
    "        img = self.aug.augment_image(img)\n",
    "        img = np.transpose(img, [2, 0, 1]) / np.max(img)\n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestAugTransform:\n",
    "    def __init__(self):\n",
    "        self.aug = iaa.Sequential([\n",
    "            iaa.Scale((IMAGE_SHAPE, IMAGE_SHAPE)),\n",
    "        ])\n",
    "      \n",
    "    def __call__(self, img):\n",
    "        img = np.array(img)\n",
    "        img = self.aug.augment_image(img)\n",
    "        img = np.transpose(img, [2, 0, 1]) / np.max(img)\n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\python\\lib\\site-packages\\imgaug\\imgaug.py:184: DeprecationWarning: Function `Scale()` is deprecated. Use `Resize` instead. Resize has the exactly same interface as Scale.\n",
      "  warn_deprecated(msg, stacklevel=3)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "human_dataset1 = ImageFolder(train_path, transform=TrainAugTransform(-12))\n",
    "human_dataset2 = ImageFolder(train_path, transform=TrainAugTransform(0))\n",
    "human_dataset3 = ImageFolder(train_path, transform=TrainAugTransform(12))\n",
    "human_dataset = ConcatDataset([human_dataset1, human_dataset2, human_dataset3])\n",
    "\n",
    "data_loader = DataLoader(human_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(ImageFolder(val_path, transform=TestAugTransform()), batch_size=BATCH_SIZE, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "class SimpleVGGClassifier(nn.Module):\n",
    "    def __init__(self, image_shape):\n",
    "        super().__init__()\n",
    "        self.kernel_size = 3\n",
    "        self.conv1 = self.conv_block(3, 64, 2)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.conv2 = self.conv_block(64, 128, 3)\n",
    "        self.bn2 = nn.BatchNorm2d(128)\n",
    "        self.conv3 = self.conv_block(128, 256, 4)\n",
    "        self.bn3 = nn.BatchNorm2d(256)\n",
    "        self.conv4 = self.conv_block(256, 512, 4)\n",
    "        self.bn4 = nn.BatchNorm2d(512)\n",
    "        # n x 512 x 14 x 14\n",
    "\n",
    "        self.linear1 = nn.Linear(512 * 14 * 14, 1000)\n",
    "        self.lrelu1 = nn.LeakyReLU()\n",
    "        self.drop1 = nn.Dropout(p=0.3)\n",
    "        self.linear2 = nn.Linear(1000, 1000)\n",
    "        self.lrelu2 = nn.LeakyReLU()\n",
    "        self.drop2 = nn.Dropout(p=0.3)\n",
    "        self.linear3 = nn.Linear(1000, 2)\n",
    "        \n",
    "    def conv_block(self, start_volume, end_volume, num_conv=1) -> nn.Module:\n",
    "        block = nn.Sequential()\n",
    "        for i in range(num_conv):\n",
    "            name_conv, name_relu = 'conv_{}_{}'.format(i, start_volume), 'relu_{}'.format(i)\n",
    "            block.add_module(name_conv, nn.Conv2d(start_volume if i == 0 else end_volume, \n",
    "                                                  end_volume, \n",
    "                                                  self.kernel_size,\n",
    "                                                  padding=1))\n",
    "            block.add_module(name_relu, nn.ReLU())\n",
    "        name_pool = 'pool_{}'.format(start_volume)\n",
    "        block.add_module(name_pool, nn.MaxPool2d(kernel_size=2))\n",
    "        return block\n",
    "\n",
    "    def forward(self, input):\n",
    "        x = self.conv1(input)\n",
    "        x = self.bn1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.bn3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = self.bn4(x)\n",
    "        x = self.linear1(x.view(input.shape[0], -1))\n",
    "        x = self.lrelu1(x)\n",
    "        x = self.drop1(x)\n",
    "        x = self.linear2(x)\n",
    "        x = self.lrelu2(x)\n",
    "        x = self.drop2(x)\n",
    "        x = self.linear3(x)\n",
    "        return F.softmax(x, dim=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import Adagrad\n",
    "\n",
    "model = SimpleVGGClassifier(IMAGE_SHAPE).cuda() if use_cuda else SimpleVGGClassifier(IMAGE_SHAPE)\n",
    "opt = Adagrad(model.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/397 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([12, 3, 224, 224]) tensor([[[0.4941, 0.5098, 0.5137,  ..., 0.1137, 0.1216, 0.1333],\n",
      "         [0.4980, 0.5098, 0.5098,  ..., 0.1098, 0.1412, 0.1529],\n",
      "         [0.4980, 0.5059, 0.5176,  ..., 0.1765, 0.1333, 0.0863],\n",
      "         ...,\n",
      "         [0.0196, 0.0196, 0.0353,  ..., 0.1098, 0.1137, 0.1176],\n",
      "         [0.0196, 0.0196, 0.0667,  ..., 0.1255, 0.1137, 0.1137],\n",
      "         [0.0235, 0.0235, 0.1020,  ..., 0.1255, 0.1098, 0.1059]],\n",
      "\n",
      "        [[0.5843, 0.6000, 0.6039,  ..., 0.2078, 0.2157, 0.2196],\n",
      "         [0.5882, 0.6000, 0.6000,  ..., 0.2000, 0.2314, 0.2314],\n",
      "         [0.5882, 0.5961, 0.6078,  ..., 0.2627, 0.2118, 0.1412],\n",
      "         ...,\n",
      "         [0.0431, 0.0431, 0.0471,  ..., 0.1529, 0.1569, 0.1490],\n",
      "         [0.0353, 0.0392, 0.0667,  ..., 0.1608, 0.1490, 0.1569],\n",
      "         [0.0353, 0.0275, 0.0941,  ..., 0.1608, 0.1490, 0.1490]],\n",
      "\n",
      "        [[0.6549, 0.6706, 0.6745,  ..., 0.3020, 0.3137, 0.3216],\n",
      "         [0.6588, 0.6706, 0.6706,  ..., 0.2941, 0.3216, 0.3098],\n",
      "         [0.6588, 0.6667, 0.6784,  ..., 0.3373, 0.2824, 0.1961],\n",
      "         ...,\n",
      "         [0.0706, 0.0667, 0.0706,  ..., 0.1569, 0.1608, 0.1686],\n",
      "         [0.0588, 0.0588, 0.0824,  ..., 0.1647, 0.1608, 0.1725],\n",
      "         [0.0510, 0.0471, 0.0980,  ..., 0.1647, 0.1608, 0.1647]]],\n",
      "       dtype=torch.float64) kek tensor([0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "for batch, labels in tqdm(data_loader, file=sys.stderr):\n",
    "    print(batch.shape, batch[0], \"kek\", labels)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 4/397 [01:27<2:23:08, 21.85s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-21-5bc4304f437c>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      9\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     10\u001B[0m     \u001B[0mmodel\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mmodel\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtrain\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 11\u001B[1;33m     \u001B[1;32mfor\u001B[0m \u001B[0mbatch\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mlabels\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mtqdm\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdata_loader\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mfile\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0msys\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mstderr\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     12\u001B[0m         \u001B[0mopt\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mzero_grad\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     13\u001B[0m         \u001B[0mcuda_batch\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mbatch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtype\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdtype\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32md:\\python\\lib\\site-packages\\tqdm\\std.py\u001B[0m in \u001B[0;36m__iter__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1164\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1165\u001B[0m         \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1166\u001B[1;33m             \u001B[1;32mfor\u001B[0m \u001B[0mobj\u001B[0m \u001B[1;32min\u001B[0m \u001B[0miterable\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1167\u001B[0m                 \u001B[1;32myield\u001B[0m \u001B[0mobj\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1168\u001B[0m                 \u001B[1;31m# Update and possibly print the progressbar.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32md:\\python\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001B[0m in \u001B[0;36m__next__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    433\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_sampler_iter\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    434\u001B[0m             \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_reset\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 435\u001B[1;33m         \u001B[0mdata\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_next_data\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    436\u001B[0m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_num_yielded\u001B[0m \u001B[1;33m+=\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    437\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_dataset_kind\u001B[0m \u001B[1;33m==\u001B[0m \u001B[0m_DatasetKind\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mIterable\u001B[0m \u001B[1;32mand\u001B[0m\u001B[0;31m \u001B[0m\u001B[0;31m\\\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32md:\\python\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001B[0m in \u001B[0;36m_next_data\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    473\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0m_next_data\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    474\u001B[0m         \u001B[0mindex\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_next_index\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m  \u001B[1;31m# may raise StopIteration\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 475\u001B[1;33m         \u001B[0mdata\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_dataset_fetcher\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfetch\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mindex\u001B[0m\u001B[1;33m)\u001B[0m  \u001B[1;31m# may raise StopIteration\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    476\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_pin_memory\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    477\u001B[0m             \u001B[0mdata\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0m_utils\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpin_memory\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpin_memory\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdata\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32md:\\python\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001B[0m in \u001B[0;36mfetch\u001B[1;34m(self, possibly_batched_index)\u001B[0m\n\u001B[0;32m     42\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mfetch\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mpossibly_batched_index\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     43\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mauto_collation\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 44\u001B[1;33m             \u001B[0mdata\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdataset\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0midx\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;32mfor\u001B[0m \u001B[0midx\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mpossibly_batched_index\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     45\u001B[0m         \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     46\u001B[0m             \u001B[0mdata\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdataset\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mpossibly_batched_index\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32md:\\python\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001B[0m in \u001B[0;36m<listcomp>\u001B[1;34m(.0)\u001B[0m\n\u001B[0;32m     42\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mfetch\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mpossibly_batched_index\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     43\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mauto_collation\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 44\u001B[1;33m             \u001B[0mdata\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdataset\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0midx\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;32mfor\u001B[0m \u001B[0midx\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mpossibly_batched_index\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     45\u001B[0m         \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     46\u001B[0m             \u001B[0mdata\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdataset\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mpossibly_batched_index\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32md:\\python\\lib\\site-packages\\torch\\utils\\data\\dataset.py\u001B[0m in \u001B[0;36m__getitem__\u001B[1;34m(self, idx)\u001B[0m\n\u001B[0;32m    216\u001B[0m         \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    217\u001B[0m             \u001B[0msample_idx\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0midx\u001B[0m \u001B[1;33m-\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcumulative_sizes\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mdataset_idx\u001B[0m \u001B[1;33m-\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 218\u001B[1;33m         \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdatasets\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mdataset_idx\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0msample_idx\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    219\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    220\u001B[0m     \u001B[1;33m@\u001B[0m\u001B[0mproperty\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32md:\\python\\lib\\site-packages\\torchvision\\datasets\\folder.py\u001B[0m in \u001B[0;36m__getitem__\u001B[1;34m(self, index)\u001B[0m\n\u001B[0;32m    151\u001B[0m         \u001B[0msample\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mloader\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mpath\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    152\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtransform\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 153\u001B[1;33m             \u001B[0msample\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtransform\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0msample\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    154\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtarget_transform\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    155\u001B[0m             \u001B[0mtarget\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtarget_transform\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtarget\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m<ipython-input-16-6d2203f383ad>\u001B[0m in \u001B[0;36m__call__\u001B[1;34m(self, img)\u001B[0m\n\u001B[0;32m     11\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     12\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0m__call__\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mimg\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 13\u001B[1;33m         \u001B[0mimg\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0marray\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mimg\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     14\u001B[0m         \u001B[0mimg\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0maug\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0maugment_image\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mimg\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     15\u001B[0m         \u001B[0mimg\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtranspose\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mimg\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;36m2\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m0\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m/\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmax\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mimg\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "train_loss, val_loss = [], []\n",
    "\n",
    "for i in range(NUM_EPOCHS):\n",
    "    tmp_train_loss, tmp_val_loss = [], []\n",
    "\n",
    "    model = model.train()\n",
    "    for batch, labels in tqdm(data_loader, file=sys.stderr):\n",
    "        opt.zero_grad()\n",
    "        cuda_batch = batch.type(dtype)\n",
    "        cuda_labels = labels.type(dtype)\n",
    "        result = model(cuda_batch)\n",
    "        loss = F.binary_cross_entropy(result[:, 1], cuda_labels)\n",
    "        tmp_train_loss.append(loss.item())\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "    \n",
    "    val_model_result = np.zeros((len(val_loader) * BATCH_SIZE, 2))\n",
    "\n",
    "    model = model.eval()\n",
    "    for i, (batch, labels) in enumerate(tqdm(val_loader, file=sys.stderr)):\n",
    "        with torch.no_grad():\n",
    "            cuda_batch = batch.type(dtype)\n",
    "            cuda_labels = labels.type(dtype)\n",
    "            result = model(cuda_batch)\n",
    "            val_model_result[i * BATCH_SIZE:i * BATCH_SIZE + len(result)] = result.clone().detach().cpu()\n",
    "            loss = F.binary_cross_entropy(result[:, 1], cuda_labels)\n",
    "            tmp_val_loss.append(loss.item())\n",
    "\n",
    "    train_loss.append(np.mean(tmp_train_loss))\n",
    "    val_loss.append(np.mean(tmp_val_loss))\n",
    "\n",
    "    print(f'[INFO] Train loss: {train_loss[-1]}, Validation loss: {val_loss[-1]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "val_model_result = np.zeros(len(val_loader) * BATCH_SIZE)\n",
    "real_targets = np.zeros(len(val_loader) * BATCH_SIZE)\n",
    "\n",
    "model = model.eval()\n",
    "for i, (batch, labels) in enumerate(val_loader):\n",
    "    with torch.no_grad():\n",
    "        cuda_batch = batch.type(dtype)\n",
    "        cuda_labels = labels.type(dtype)\n",
    "        result = model(cuda_batch)\n",
    "        print(labels, result)\n",
    "        _res = result.clone().detach().cpu().numpy().argmax(axis=1)\n",
    "        val_model_result[(i * BATCH_SIZE):(i * BATCH_SIZE + len(result))] = _res\n",
    "        real_targets[(i * BATCH_SIZE):(i * BATCH_SIZE + len(result))] = labels\n",
    "        loss = F.binary_cross_entropy(result[:, 1], cuda_labels)\n",
    "        tmp_val_loss.append(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "val_model_result, real_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(classification_report(real_targets, val_model_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), os.path.join(os.getcwd(), 'model.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_model_result, real_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(real_targets, val_model_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), os.path.join(os.getcwd(), 'model.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}